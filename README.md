# FeatureEngineering
![introduction-image-1024x367](https://user-images.githubusercontent.com/123563634/234850653-be7e40e6-2e8a-4167-ac9d-61a7788ad58b.jpg)

Feature engineering is the process of selecting, manipulating, and transforming raw data into features that can be used in supervised learning.

ðŸ‘‰ **What is Feature Engineering?**

  Feature engineering is a machine learning technique that leverages data to create new variables that arenâ€™t in the training set. It can produce new features for both supervised and unsupervised learning, with the goal of simplifying and speeding up data transformations while also enhancing model accuracy. Feature engineering is required when working with machine learning models. Regardless of the data or architecture, a terrible feature will have a direct impact on your model.

ðŸ‘‰ **Importance Of Feature Engineering**

   Feature Engineering is a very important step in machine learning. Feature engineering refers to the process of designing artificial features into an algorithm. These artificial features are then used by that algorithm in order to improve its performance, or in other words reap better results. Data scientists spend most of their time with data, and it becomes important to make models accurate.

ðŸ‘‰ **Steps in Feature Engineering**

The steps of feature engineering may vary as per different data scientists and ML engineers. However, there are some common steps that are involved in most machine learning algorithms, and these steps are as follows:

- **Data Preparation:** The first step is data preparation. In this step, raw data acquired from different resources are prepared to make it in a suitable format so that it can be used in the ML model. The data preparation may contain cleaning of data, delivery, data augmentation, fusion, ingestion, or loading.

- **Exploratory Analysis:** Exploratory analysis or Exploratory data analysis (EDA) is an important step of features engineering, which is mainly used by data scientists. This step involves analysis, investing data set, and summarization of the main characteristics of data. Different data visualization techniques are used to better understand the manipulation of data sources, to find the most appropriate statistical technique for data analysis, and to select the best features for the data.

- **Benchmark:** Benchmarking is a process of setting a standard baseline for accuracy to compare all the variables from this baseline. The benchmarking process is used to improve the predictability of the model and reduce the error rate.

ðŸ‘‰ **Topics Covered in Repository**

- [Dummy Variable](https://www.kaggle.com/code/themrityunjaypathak/dummy-variable)
- [Inter Quartile Range](https://www.kaggle.com/code/themrityunjaypathak/removing-outlier-from-data-using-iqr)
- [Z-Score](https://www.kaggle.com/code/themrityunjaypathak/removing-outlier-from-data-using-zscore)
- [Modified Z-Score](https://www.kaggle.com/code/themrityunjaypathak/removing-outlier-from-data-using-modified-zscore)
- [Data Standardization](https://www.kaggle.com/code/themrityunjaypathak/data-standardization)
